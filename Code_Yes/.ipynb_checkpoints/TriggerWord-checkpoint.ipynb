{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4---เริ่มทำการตรวจจับคำ trigger word detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ต้องติดตั้ง Module รัน pyaudio เพื่อทำการอัดเสียงผ่านคำสั่ง Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pipwin\n",
    "!pipwin install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install playsound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from pydub import AudioSegment\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import IPython\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import wave\n",
    "from n_utils import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
    "from keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io.wavfile import write\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a pre-train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('D:/Babie/DetectHelp/Code_No/models/No_8.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect trigger word functions\n",
    "##### โหลดโมเดลมาไว้ใน Func- detect_triggerword_spectrum เพื่อเอาไปเช็คใน Audio stream เมื่อเจอคำว่า \"ช่วยด้วย\" แสดง \"Do you need help? \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_triggerword_spectrum(x):\n",
    "\n",
    "    x  = x.swapaxes(0,1)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    predictions = model.predict(x)\n",
    "    return predictions.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_new_triggerword(predictions, chunk_duration, feed_duration, threshold=0.2):\n",
    "\n",
    "    predictions = predictions > threshold\n",
    "    \n",
    "    chunk_predictions_samples = int(len(predictions) * chunk_duration / feed_duration)\n",
    "    chunk_predictions = predictions[-chunk_predictions_samples:]\n",
    "    level = chunk_predictions[0]\n",
    "    for predictions in chunk_predictions:\n",
    "        if predictions > level:\n",
    "            return True\n",
    "        else:\n",
    "            level = predictions\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record audio stream from mic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_duration = 0.5\n",
    "fs = 44100 \n",
    "chunk_samples = int(fs * chunk_duration)\n",
    "\n",
    "feed_duration = 10\n",
    "feed_samples = int(fs * feed_duration)\n",
    "\n",
    "assert feed_duration/chunk_duration == int(feed_duration/chunk_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(data):\n",
    "\n",
    "    nfft = 200 \n",
    "    fs = 8000 \n",
    "    noverlap = 120\n",
    "    nchannels = data.ndim\n",
    "    if nchannels == 1:\n",
    "        pxx, _, _ = mlab.specgram(data, nfft, fs, noverlap = noverlap)\n",
    "    elif nchannels == 2:\n",
    "        pxx, _, _ = mlab.specgram(data[:,0], nfft, fs, noverlap = noverlap)\n",
    "    return pxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_spectrogram(data):\n",
    "\n",
    "    nfft = 200\n",
    "    fs = 8000\n",
    "    noverlap = 120 \n",
    "    nchannels = data.ndim\n",
    "    if nchannels == 1:\n",
    "        pxx, _, _, _ = plt.specgram(data, nfft, fs, noverlap = noverlap)\n",
    "    elif nchannels == 2:\n",
    "        pxx, _, _, _ = plt.specgram(data[:,0], nfft, fs, noverlap = noverlap)\n",
    "    return pxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_input_stream(callback):\n",
    "    stream = pyaudio.PyAudio().open(\n",
    "        format=pyaudio.paInt16,\n",
    "        channels=1,\n",
    "        rate=fs,\n",
    "        input=True,\n",
    "        frames_per_buffer=chunk_samples,\n",
    "        input_device_index=1,\n",
    "        stream_callback=callback)\n",
    "    return stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio stream โดย Detect \"ไม่\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---.-..No\n",
      "----.--.--..-..No\n",
      ".-..-.----.--..-No\n",
      "--.---.--.No\n",
      ".-..-------."
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "import sys\n",
    "import time\n",
    "from playsound import playsound\n",
    "\n",
    "q = Queue()\n",
    "run = True\n",
    "silence_threshold = 500\n",
    "\n",
    "timeout = time.time() + 0.5*60 #อัดเสียง 30 วินาที\n",
    "\n",
    "data = np.zeros(feed_samples, dtype='int16')\n",
    "\n",
    "def callback(in_data, frame_count, time_info, status):\n",
    "    global run, timeout, data, silence_threshold    \n",
    "    if time.time() > timeout:\n",
    "        run = False        \n",
    "    data0 = np.frombuffer(in_data, dtype='int16')\n",
    "    if np.abs(data0).mean() < silence_threshold:\n",
    "        sys.stdout.write('-')\n",
    "        return (in_data, pyaudio.paContinue)\n",
    "    else:\n",
    "        sys.stdout.write('.')\n",
    "    data = np.append(data,data0)    \n",
    "    if len(data) > feed_samples:\n",
    "        data = data[-feed_samples:]\n",
    "        q.put(data)\n",
    "    return (in_data, pyaudio.paContinue)\n",
    "\n",
    "stream = get_audio_input_stream(callback)\n",
    "stream.start_stream()\n",
    "\n",
    "try:\n",
    "    while run:\n",
    "        data = q.get()\n",
    "        spectrum = get_spectrogram(data)\n",
    "        preds = detect_triggerword_spectrum(spectrum)\n",
    "        new_trigger = has_new_triggerword(preds, chunk_duration, feed_duration)\n",
    "        if new_trigger:\n",
    "            print('No')\n",
    "            playsound('output2.wav')\n",
    "#         data = q.delete()\n",
    "\n",
    "except (KeyboardInterrupt, SystemExit):\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    timeout = time.time()\n",
    "    run = False\n",
    "        \n",
    "stream.stop_stream()\n",
    "stream.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## เป็นส่วนแสดงค่า silence_threshold ของเสียงที่ Audio stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.71950113378685\n",
      "66.7372335600907\n",
      "74.83006802721088\n",
      "75.8962358276644\n",
      "66.6459410430839\n",
      "63.49836734693878\n",
      "55.67038548752834\n",
      "54.641950113378684\n",
      "63.65546485260771\n",
      "71.07006802721088\n",
      "70.15201814058958\n",
      "72.77083900226758\n",
      "116.3318820861678\n",
      "316.22544217687073\n",
      "71.17120181405896\n",
      "67.1766439909297\n",
      "56.85845804988662\n",
      "73.42077097505668\n",
      "118.30362811791383\n",
      "87.92707482993197\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "data_c = None\n",
    "\n",
    "def callback(in_data, frame_count, time_info, status):\n",
    "    global data_c\n",
    "    data_c = np.frombuffer(in_data, dtype='int16')\n",
    "    print( np.abs(data_c).mean())\n",
    "    return (in_data, pyaudio.paContinue)\n",
    "\n",
    "stream = pyaudio.PyAudio().open(\n",
    "    format=pyaudio.paInt16,\n",
    "    channels=1,\n",
    "    rate=fs,\n",
    "    input=True,\n",
    "    frames_per_buffer=chunk_samples,\n",
    "    input_device_index=0,\n",
    "    stream_callback=callback)\n",
    "stream.start_stream()\n",
    "time.sleep(10.1)\n",
    "stream.stop_stream()\n",
    "stream.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pxx = plt_spectrogram(data_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## เป็นส่วนบันทึกเสียงที่ Audio stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write('D:/Babie/DetectHelp/TestSound/test5.wav', 44100, data_c)\n",
    "\n",
    "samplerate = 44100 #44.1 kHz\n",
    "fs = 100\n",
    "t = np.linspace(0., 30. , samplerate)\n",
    "amplitude = np.iinfo(np.int16).max\n",
    "data_c = amplitude * np.sin(2. * np.pi * fs * t)\n",
    "write(\"D:/Babie/DetectHelp/TestSound/test6.wav\", samplerate, data.astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(\"D:/Babie/DetectHelp/TestSound/test6.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
